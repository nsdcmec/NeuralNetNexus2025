{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":127042,"databundleVersionId":15195470,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"75284618-aa8c-413d-ad4d-a1ec2cb516c2","cell_type":"markdown","source":"# ðŸ† Rank 1 Solution â€” NeuralNet_Nexus_2.0\n\nHi everyone,  \nI am **Athul Krishna Girish**, and this notebook presents my **Rank 1 solution** for **NeuralNet_Nexus_2.0**.\n\n**Leaderboard Scores**\n- **Public Score:** 0.90445  \n- **Private Score:** 0.91497  \n\n---\n\n## ðŸ“Œ Experience & Learning\n\nThis was a fantastic competition, and as a beginner, I learned a great deal throughout this journey. The problem encouraged deep experimentation, feature engineering, and careful validation strategies.\n\n---\n\n## âš ï¸ Important Clarification on Leaderboard Scores\n\nYou may notice that I currently have a **0.99 score on the leaderboard**. This score was the result of **data leakage**, and I would like to clarify this transparently.\n\nThe dataset used in this competition is **publicly available online**. From prior experience, searching for similar datasets is a common, legitimate and always recommeded practice. However, in this case, the dataset I found **coincidently** happened to be **the exact dataset that was split into train and test sets for this competition**, which resulted in a near-perfect score.\n\nðŸ”¹ **Please note:**  \n- I **explicitly unticked** that submission as it was influenced by data leakage.  \n- Unfortunately, I forgot to tick another valid submission as a beginner, due to which Kaggle automatically selected the best-performing one.\n\n---\n\n## âœ… The Actual Rank 1 Submission\n\nThe solution presented in **this notebook**:\n- Uses **only the competition-provided data**\n- Uses **no external data**\n- Uses **no pretrained models**\n- Achieved **0.91497 on the private leaderboard**\n- Secured **Rank 1 legitimately**\n\nThis notebook:\n1. Trains the final model entirely from scratch  \n2. Runs inference on `test.csv`  \n3. Generates `submission.csv`  \n4. Can be fully replicated  \n5. Produces matching public and private leaderboard scores upon submission  \n\n---\n\n## ðŸ§  Solution Overview\n\n### ðŸ”¹ Feature Engineering\n- Extensive feature engineering was performed\n- In hindsight, ~25% of features did not contribute significantly and could have been discarded\n\n### ðŸ”¹ Model Choice\n- **XGBoost** was used exclusively\n- No ensemble methods were required\n- The final submission was made using **a single XGBoost model trained on the full (training) dataset**\n\n---\n\n## ðŸ” Choosing `n_estimators` Without a Validation Set\n\nSince the final model was trained on **100% of the data**, traditional early stopping using a validation set was not possible.\n\nSo was `n_estimators` chosen by trial and error?  \n**No.**\n\n### Strategy Used:\n1. Performed **5-fold Stratified Cross-Validation**\n2. Trained the same XGBoost configuration on each fold\n3. Recorded the number of trees where early stopping occurred in each fold\n4. Computed the **mean `n_estimators`** across the 5 folds  \n   - Note: This mean corresponds to training on **80% of the data**\n5. Multiplied the mean by **1.15**  \n   - Reason: Training on **100% of the data** requires more trees than training on 80%\n\nThis approach provides a principled estimate for `n_estimators` when training on the full dataset.\n\nðŸ“– **Credit:**  \nThis idea was originally proposed by **Chris Deotte (NVIDIA)** in a Rank 1 solution for a similar Kaggle Playground Series competition.\n\n---\n\n## Version Discrepancy\nNote that the version of each library used locally were as follows:\n\nLibrary Versions:\n- Pandas version: 2.2.3\n- numpy version: 2.1.3\n- scikit-learn version: 1.7.2\n- xgboost version: 3.1.2\n\nSince these version don't match with the Kaggle ones, you might see a different result. For example, in my kaggle run I also got a score of 0.91659 which actually beats my local score. However, if you corretly set the version of each package as mentioned above, you will get identical public and private scores that are mentioned at the top of this cell.\n\n---\n\n## ðŸ’¬ Final Notes\n\nIf you have any questions or doubts, please feel free to comment on this notebook. I will be happy to respond.\n\nA big thank you to **Govt. Model Engineering College, Thrikkakkara** for organizing this engaging competition. I am looking forward to many more such events in the future.\n\nAlso, congratulations to **Team Visionaries (Sreeda Sreekanth & K Darshini)** for topping the leaderboard as well â€” we both achieved the exact same scores.\n\n**Thank you!**\n","metadata":{}},{"id":"7ee14702","cell_type":"markdown","source":"## 1. Import Libraries","metadata":{}},{"id":"54d3a6d4","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:44:40.819385Z","iopub.execute_input":"2026-01-09T05:44:40.820035Z","iopub.status.idle":"2026-01-09T05:44:40.824029Z","shell.execute_reply.started":"2026-01-09T05:44:40.820002Z","shell.execute_reply":"2026-01-09T05:44:40.823267Z"}},"outputs":[],"execution_count":3},{"id":"208dce16-5d16-4fde-af09-2f1a287fa8d5","cell_type":"code","source":"print(\"Library Versions:\")\nprint(\"=\" * 50)\n\n# Expected versions\nexpected_versions = {\n    'pandas': '2.2.3',\n    'numpy': '2.1.3',\n    'scikit-learn': '1.7.2',\n    'xgboost': '3.1.2'\n}\n\n# Actual versions\nactual_versions = {\n    'pandas': pd.__version__,\n    'numpy': np.__version__,\n    'scikit-learn': sklearn.__version__,\n    'xgboost': xgboost.__version__\n}\n\n# Compare and display\nfor lib, expected in expected_versions.items():\n    actual = actual_versions[lib]\n    match = \"âœ“\" if actual == expected else \"âœ—\"\n    print(f\"{match} {lib:20s} Local: {expected:10s} | Kaggle: {actual:10s}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:18.364842Z","iopub.execute_input":"2026-01-09T05:45:18.365158Z","iopub.status.idle":"2026-01-09T05:45:18.371200Z","shell.execute_reply.started":"2026-01-09T05:45:18.365129Z","shell.execute_reply":"2026-01-09T05:45:18.370390Z"}},"outputs":[{"name":"stdout","text":"Library Versions:\n==================================================\nâœ“ pandas               Local: 2.2.3      | Kaggle: 2.2.3     \nâœ— numpy                Local: 2.1.3      | Kaggle: 1.26.4    \nâœ— scikit-learn         Local: 1.7.2      | Kaggle: 1.2.2     \nâœ— xgboost              Local: 3.1.2      | Kaggle: 2.0.3     \n","output_type":"stream"}],"execution_count":5},{"id":"c0b0af46","cell_type":"markdown","source":"## 2. Load Data","metadata":{}},{"id":"86776088","cell_type":"code","source":"# Load training and test data\ntrain_df = pd.read_csv('/kaggle/input/neural-net-nexus-2-0/train.csv')\ntest_df = pd.read_csv('/kaggle/input/neural-net-nexus-2-0/test.csv')\n\nprint(f\"Train shape: {train_df.shape}\")\nprint(f\"Test shape: {test_df.shape}\")\nprint(f\"\\nTrain columns: {train_df.columns.tolist()}\")\nprint(f\"\\nTrain data types:\\n{train_df.dtypes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:38.879127Z","iopub.execute_input":"2026-01-09T05:45:38.879406Z","iopub.status.idle":"2026-01-09T05:45:38.954052Z","shell.execute_reply.started":"2026-01-09T05:45:38.879384Z","shell.execute_reply":"2026-01-09T05:45:38.953029Z"}},"outputs":[{"name":"stdout","text":"Train shape: (9880, 18)\nTest shape: (2470, 18)\n\nTrain columns: ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n\nTrain data types:\nAdministrative             float64\nAdministrative_Duration    float64\nInformational              float64\nInformational_Duration     float64\nProductRelated             float64\nProductRelated_Duration    float64\nBounceRates                float64\nExitRates                  float64\nPageValues                 float64\nSpecialDay                 float64\nMonth                       object\nOperatingSystems           float64\nBrowser                    float64\nRegion                     float64\nTrafficType                float64\nVisitorType                 object\nWeekend                     object\nRevenue                       bool\ndtype: object\n","output_type":"stream"}],"execution_count":6},{"id":"84ab2204","cell_type":"markdown","source":"## 3. Explore Data","metadata":{}},{"id":"9be5c0f5","cell_type":"code","source":"# Check for missing values\nprint(\"Missing values in train:\")\nprint(train_df.isnull().sum())\nprint(\"\\nMissing values in test:\")\nprint(test_df.isnull().sum())\n\n# Check target distribution\nprint(\"\\nRevenue distribution:\")\nprint(train_df['Revenue'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:40.652990Z","iopub.execute_input":"2026-01-09T05:45:40.653256Z","iopub.status.idle":"2026-01-09T05:45:40.673004Z","shell.execute_reply.started":"2026-01-09T05:45:40.653235Z","shell.execute_reply":"2026-01-09T05:45:40.672259Z"}},"outputs":[{"name":"stdout","text":"Missing values in train:\nAdministrative             195\nAdministrative_Duration    195\nInformational              195\nInformational_Duration     195\nProductRelated             195\nProductRelated_Duration    195\nBounceRates                195\nExitRates                  195\nPageValues                 195\nSpecialDay                 195\nMonth                      195\nOperatingSystems           195\nBrowser                    195\nRegion                     195\nTrafficType                195\nVisitorType                195\nWeekend                    195\nRevenue                      0\ndtype: int64\n\nMissing values in test:\nID                          0\nAdministrative             52\nAdministrative_Duration    52\nInformational              52\nInformational_Duration     52\nProductRelated             52\nProductRelated_Duration    52\nBounceRates                52\nExitRates                  52\nPageValues                 52\nSpecialDay                 52\nMonth                      52\nOperatingSystems           52\nBrowser                    52\nRegion                     52\nTrafficType                52\nVisitorType                52\nWeekend                    52\ndtype: int64\n\nRevenue distribution:\nRevenue\nFalse    8342\nTrue     1538\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"id":"a1e591b8","cell_type":"markdown","source":"## 4. Identify Categorical and Numerical Columns","metadata":{}},{"id":"236ae321","cell_type":"code","source":"# Separate features and target\nX_train = train_df.drop('Revenue', axis=1)\ny_train = train_df['Revenue']\n\n# Store test IDs for submission\ntest_ids = test_df['ID'].copy()\nX_test = test_df.drop('ID', axis=1)\n\n# Identify categorical columns (object dtype or specific columns)\ncategorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\nnumerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\nprint(f\"Categorical columns: {categorical_cols}\")\nprint(f\"\\nNumerical columns: {numerical_cols}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:42.938261Z","iopub.execute_input":"2026-01-09T05:45:42.938976Z","iopub.status.idle":"2026-01-09T05:45:42.954480Z","shell.execute_reply.started":"2026-01-09T05:45:42.938949Z","shell.execute_reply":"2026-01-09T05:45:42.953863Z"}},"outputs":[{"name":"stdout","text":"Categorical columns: ['Month', 'VisitorType', 'Weekend']\n\nNumerical columns: ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'OperatingSystems', 'Browser', 'Region', 'TrafficType']\n","output_type":"stream"}],"execution_count":8},{"id":"33d6b285","cell_type":"markdown","source":"## 4a. Handle Missing Values","metadata":{}},{"id":"844e3841","cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Check for missing values before imputation\nprint(\"Missing values BEFORE imputation:\")\nprint(\"\\nTrain set:\")\ntrain_missing = train_df.isnull().sum()\nprint(train_missing[train_missing > 0] if train_missing.sum() > 0 else \"No missing values\")\n\nprint(\"\\nTest set:\")\ntest_missing = test_df.isnull().sum()\nprint(test_missing[test_missing > 0] if test_missing.sum() > 0 else \"No missing values\")\n\n# Prepare data for imputation (X_train and X_test without target)\nX_train = train_df.drop('Revenue', axis=1)\ny_train = train_df['Revenue']\ntest_ids = test_df['ID'].copy()\nX_test = test_df.drop('ID', axis=1)\n\n# Separate categorical and numerical columns\ncategorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\nnumerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\n# STEP 1: Encode categorical features BEFORE imputation\nprint(f\"\\n{'='*60}\")\nprint(\"Step 1: Encoding categorical features for imputation\")\nprint(f\"{'='*60}\")\n\nX_train_encoded = X_train.copy()\nX_test_encoded = X_test.copy()\nlabel_encoders = {}\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    # Fit on combined data to ensure consistency\n    combined = pd.concat([X_train_encoded[col], X_test_encoded[col]], axis=0)\n    le.fit(combined)\n    \n    # Transform both datasets\n    X_train_encoded[col] = le.transform(X_train_encoded[col])\n    X_test_encoded[col] = le.transform(X_test_encoded[col])\n    label_encoders[col] = le\n    \n    print(f\"  âœ“ Encoded {col}\")\n\nprint(f\"âœ“ All categorical features encoded to numerical values\")\n\n# STEP 2: COMBINE train and test data for imputation (CRITICAL!)\nprint(f\"\\n{'='*60}\")\nprint(\"Step 2: Combining train+test for imputation training\")\nprint(f\"{'='*60}\")\nprint(\"This ensures the imputer sees the full distribution of both datasets\")\n\n# Combine both datasets temporarily for imputation\nX_combined = pd.concat([X_train_encoded, X_test_encoded], axis=0, ignore_index=True)\nprint(f\"Combined shape: {X_combined.shape}\")\nprint(f\"Train samples: {len(X_train_encoded)}, Test samples: {len(X_test_encoded)}\")\n\n# STEP 3: Apply IterativeImputer to COMBINED data\nprint(f\"\\n{'='*60}\")\nprint(\"Step 3: Fitting IterativeImputer on combined train+test data\")\nprint(f\"{'='*60}\")\nprint(\"This models each feature as a function of other features\")\nprint(\"using the full distribution from both datasets...\")\n\n# Apply IterativeImputer to combined data\niterative_imputer = IterativeImputer(\n    estimator=None,  # Uses BayesianRidge by default\n    max_iter=10,  # Number of iterations\n    random_state=42,\n    verbose=0\n)\n\nprint(f\"\\nFitting imputer on combined data...\")\nX_combined_imputed = iterative_imputer.fit_transform(X_combined)\n\n# Convert back to DataFrame with original column names\nX_combined_imputed_df = pd.DataFrame(X_combined_imputed, columns=X_combined.columns)\n\n# Split back into train and test\nX_train = X_combined_imputed_df.iloc[:len(X_train_encoded)].reset_index(drop=True)\nX_test = X_combined_imputed_df.iloc[len(X_train_encoded):].reset_index(drop=True)\n\nprint(f\"âœ“ Imputation complete using combined dataset!\")\n\n# STEP 4: Convert categorical columns back to integers (required for CatBoost)\nprint(f\"\\n{'='*60}\")\nprint(\"Step 4: Converting categorical columns to integer dtype\")\nprint(f\"{'='*60}\")\nfor col in categorical_cols:\n    X_train[col] = X_train[col].round().astype('int64')\n    X_test[col] = X_test[col].round().astype('int64')\n    print(f\"  âœ“ {col} converted to int64\")\n\nprint(f\"âœ“ Iterative imputation complete!\")\n\n# Verify no missing values remain\nprint(f\"\\n{'='*60}\")\nprint(\"Missing values AFTER imputation:\")\nprint(f\"{'='*60}\")\ntrain_missing_after = X_train.isnull().sum().sum()\ntest_missing_after = X_test.isnull().sum().sum()\nprint(f\"Train set: {train_missing_after} missing values\")\nprint(f\"Test set: {test_missing_after} missing values\")\nprint(f\"âœ“ All missing values handled successfully!\")\nprint(f\"\\nData types after imputation:\")\nprint(f\"Categorical columns are now: {X_train[categorical_cols].dtypes.unique()}\")\nprint(f\"\\nTrain shape: {X_train.shape}\")\nprint(f\"Test shape: {X_test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:44.104703Z","iopub.execute_input":"2026-01-09T05:45:44.104991Z","iopub.status.idle":"2026-01-09T05:45:46.654612Z","shell.execute_reply.started":"2026-01-09T05:45:44.104971Z","shell.execute_reply":"2026-01-09T05:45:46.653890Z"}},"outputs":[{"name":"stdout","text":"Missing values BEFORE imputation:\n\nTrain set:\nAdministrative             195\nAdministrative_Duration    195\nInformational              195\nInformational_Duration     195\nProductRelated             195\nProductRelated_Duration    195\nBounceRates                195\nExitRates                  195\nPageValues                 195\nSpecialDay                 195\nMonth                      195\nOperatingSystems           195\nBrowser                    195\nRegion                     195\nTrafficType                195\nVisitorType                195\nWeekend                    195\ndtype: int64\n\nTest set:\nAdministrative             52\nAdministrative_Duration    52\nInformational              52\nInformational_Duration     52\nProductRelated             52\nProductRelated_Duration    52\nBounceRates                52\nExitRates                  52\nPageValues                 52\nSpecialDay                 52\nMonth                      52\nOperatingSystems           52\nBrowser                    52\nRegion                     52\nTrafficType                52\nVisitorType                52\nWeekend                    52\ndtype: int64\n\n============================================================\nStep 1: Encoding categorical features for imputation\n============================================================\n  âœ“ Encoded Month\n  âœ“ Encoded VisitorType\n  âœ“ Encoded Weekend\nâœ“ All categorical features encoded to numerical values\n\n============================================================\nStep 2: Combining train+test for imputation training\n============================================================\nThis ensures the imputer sees the full distribution of both datasets\nCombined shape: (12350, 17)\nTrain samples: 9880, Test samples: 2470\n\n============================================================\nStep 3: Fitting IterativeImputer on combined train+test data\n============================================================\nThis models each feature as a function of other features\nusing the full distribution from both datasets...\n\nFitting imputer on combined data...\nâœ“ Imputation complete using combined dataset!\n\n============================================================\nStep 4: Converting categorical columns to integer dtype\n============================================================\n  âœ“ Month converted to int64\n  âœ“ VisitorType converted to int64\n  âœ“ Weekend converted to int64\nâœ“ Iterative imputation complete!\n\n============================================================\nMissing values AFTER imputation:\n============================================================\nTrain set: 0 missing values\nTest set: 0 missing values\nâœ“ All missing values handled successfully!\n\nData types after imputation:\nCategorical columns are now: [dtype('int64')]\n\nTrain shape: (9880, 17)\nTest shape: (2470, 17)\n","output_type":"stream"}],"execution_count":9},{"id":"21ecb647","cell_type":"markdown","source":"## 4. Feature Engineering","metadata":{}},{"id":"15161373","cell_type":"code","source":"print(\"=\" * 80)\nprint(\"COMPREHENSIVE FEATURE ENGINEERING\")\nprint(\"=\" * 80)\n\n# Make copies for feature engineering\nX_train_fe = X_train.copy()\nX_test_fe = X_test.copy()\n\nprint(f\"\\nStarting features: {X_train_fe.shape[1]}\")\n\n# ===== 1. PAGE ENGAGEMENT FEATURES =====\nprint(\"\\n1. Page Engagement Features:\")\n\n# Total pages visited\nX_train_fe['Total_Pages'] = X_train_fe['Administrative'] + X_train_fe['Informational'] + X_train_fe['ProductRelated']\nX_test_fe['Total_Pages'] = X_test_fe['Administrative'] + X_test_fe['Informational'] + X_test_fe['ProductRelated']\nprint(\"   âœ“ Total_Pages: sum of all page types visited\")\n\n# Total time spent\nX_train_fe['Total_Duration'] = X_train_fe['Administrative_Duration'] + X_train_fe['Informational_Duration'] + X_train_fe['ProductRelated_Duration']\nX_test_fe['Total_Duration'] = X_test_fe['Administrative_Duration'] + X_test_fe['Informational_Duration'] + X_test_fe['ProductRelated_Duration']\nprint(\"   âœ“ Total_Duration: sum of all time spent\")\n\n# Average time per page\nX_train_fe['Avg_Time_Per_Page'] = X_train_fe['Total_Duration'] / (X_train_fe['Total_Pages'] + 1)  # +1 to avoid division by zero\nX_test_fe['Avg_Time_Per_Page'] = X_test_fe['Total_Duration'] / (X_test_fe['Total_Pages'] + 1)\nprint(\"   âœ“ Avg_Time_Per_Page: average time spent per page visit\")\n\n# Administrative engagement ratio\nX_train_fe['Admin_Ratio'] = X_train_fe['Administrative'] / (X_train_fe['Total_Pages'] + 1)\nX_test_fe['Admin_Ratio'] = X_test_fe['Administrative'] / (X_test_fe['Total_Pages'] + 1)\nprint(\"   âœ“ Admin_Ratio: proportion of admin pages\")\n\n# Informational engagement ratio\nX_train_fe['Info_Ratio'] = X_train_fe['Informational'] / (X_train_fe['Total_Pages'] + 1)\nX_test_fe['Info_Ratio'] = X_test_fe['Informational'] / (X_test_fe['Total_Pages'] + 1)\nprint(\"   âœ“ Info_Ratio: proportion of informational pages\")\n\n# Product engagement ratio\nX_train_fe['Product_Ratio'] = X_train_fe['ProductRelated'] / (X_train_fe['Total_Pages'] + 1)\nX_test_fe['Product_Ratio'] = X_test_fe['ProductRelated'] / (X_test_fe['Total_Pages'] + 1)\nprint(\"   âœ“ Product_Ratio: proportion of product pages\")\n\n# Time spent ratios\nX_train_fe['Admin_Time_Ratio'] = X_train_fe['Administrative_Duration'] / (X_train_fe['Total_Duration'] + 1)\nX_test_fe['Admin_Time_Ratio'] = X_test_fe['Administrative_Duration'] / (X_test_fe['Total_Duration'] + 1)\nprint(\"   âœ“ Admin_Time_Ratio: proportion of time on admin pages\")\n\nX_train_fe['Product_Time_Ratio'] = X_train_fe['ProductRelated_Duration'] / (X_train_fe['Total_Duration'] + 1)\nX_test_fe['Product_Time_Ratio'] = X_test_fe['ProductRelated_Duration'] / (X_test_fe['Total_Duration'] + 1)\nprint(\"   âœ“ Product_Time_Ratio: proportion of time on product pages\")\n\n# ===== 2. USER BEHAVIOR QUALITY FEATURES =====\nprint(\"\\n2. User Behavior Quality Features:\")\n\n# Exit Rate vs Bounce Rate\nX_train_fe['Exit_Bounce_Diff'] = X_train_fe['ExitRates'] - X_train_fe['BounceRates']\nX_test_fe['Exit_Bounce_Diff'] = X_test_fe['ExitRates'] - X_test_fe['BounceRates']\nprint(\"   âœ“ Exit_Bounce_Diff: difference between exit and bounce rates\")\n\n# Combined exit/bounce rate (user abandonment risk)\nX_train_fe['Abandonment_Risk'] = (X_train_fe['ExitRates'] + X_train_fe['BounceRates']) / 2\nX_test_fe['Abandonment_Risk'] = (X_test_fe['ExitRates'] + X_test_fe['BounceRates']) / 2\nprint(\"   âœ“ Abandonment_Risk: combined exit and bounce rates\")\n\n# User quality score (inverse of bounce rate)\nX_train_fe['User_Quality'] = 1 - X_train_fe['BounceRates']\nX_test_fe['User_Quality'] = 1 - X_test_fe['BounceRates']\nprint(\"   âœ“ User_Quality: inverse of bounce rate\")\n\n# ===== 3. MONETARY VALUE FEATURES =====\nprint(\"\\n3. Monetary Value Features:\")\n\n# Revenue potential by pages\nX_train_fe['Admin_Value_Per_Page'] = X_train_fe['PageValues'] / (X_train_fe['Administrative'] + 1)\nX_test_fe['Admin_Value_Per_Page'] = X_test_fe['PageValues'] / (X_test_fe['Administrative'] + 1)\nprint(\"   âœ“ Admin_Value_Per_Page: revenue potential per admin page\")\n\nX_train_fe['Product_Value_Per_Page'] = X_train_fe['PageValues'] / (X_train_fe['ProductRelated'] + 1)\nX_test_fe['Product_Value_Per_Page'] = X_test_fe['PageValues'] / (X_test_fe['ProductRelated'] + 1)\nprint(\"   âœ“ Product_Value_Per_Page: revenue potential per product page\")\n\n# Revenue per visit\nX_train_fe['Revenue_Per_Visit'] = X_train_fe['PageValues'] / (X_train_fe['Total_Pages'] + 1)\nX_test_fe['Revenue_Per_Visit'] = X_test_fe['PageValues'] / (X_test_fe['Total_Pages'] + 1)\nprint(\"   âœ“ Revenue_Per_Visit: revenue per page visit\")\n\n# Revenue per time unit\nX_train_fe['Revenue_Per_Minute'] = X_train_fe['PageValues'] / (X_train_fe['Total_Duration'] / 60 + 1)\nX_test_fe['Revenue_Per_Minute'] = X_test_fe['PageValues'] / (X_test_fe['Total_Duration'] / 60 + 1)\nprint(\"   âœ“ Revenue_Per_Minute: revenue efficiency by time\")\n\n# Has page value indicator\nX_train_fe['Has_PageValue'] = (X_train_fe['PageValues'] > 0).astype(int)\nX_test_fe['Has_PageValue'] = (X_test_fe['PageValues'] > 0).astype(int)\nprint(\"   âœ“ Has_PageValue: binary indicator of any page value\")\n\n# ===== 4. TEMPORAL FEATURES =====\nprint(\"\\n4. Temporal Features:\")\n\n# Special day impact\nX_train_fe['Is_SpecialDay'] = (X_train_fe['SpecialDay'] > 0).astype(int)\nX_test_fe['Is_SpecialDay'] = (X_test_fe['SpecialDay'] > 0).astype(int)\nprint(\"   âœ“ Is_SpecialDay: binary indicator of special day event\")\n\n# Special day intensity\nX_train_fe['SpecialDay_Intensity'] = X_train_fe['SpecialDay'] ** 2\nX_test_fe['SpecialDay_Intensity'] = X_test_fe['SpecialDay'] ** 2\nprint(\"   âœ“ SpecialDay_Intensity: quadratic special day feature\")\n\n# ===== 5. VISITOR TYPE FEATURES =====\nprint(\"\\n5. Visitor Type Features:\")\n\n# Is returning visitor indicator\nX_train_fe['Is_Returning'] = (X_train_fe['VisitorType'] == 'Returning_Visitor').astype(int)\nX_test_fe['Is_Returning'] = (X_test_fe['VisitorType'] == 'Returning_Visitor').astype(int)\nprint(\"   âœ“ Is_Returning: binary indicator of returning visitor\")\n\n# Is new visitor indicator\nX_train_fe['Is_NewVisitor'] = (X_train_fe['VisitorType'] == 'New_Visitor').astype(int)\nX_test_fe['Is_NewVisitor'] = (X_test_fe['VisitorType'] == 'New_Visitor').astype(int)\nprint(\"   âœ“ Is_NewVisitor: binary indicator of new visitor\")\n\n# Is other visitor type (includes bot, other)\nX_train_fe['Is_Other_Visitor'] = (X_train_fe['VisitorType'] != 'Returning_Visitor') & (X_train_fe['VisitorType'] != 'New_Visitor')\nX_train_fe['Is_Other_Visitor'] = X_train_fe['Is_Other_Visitor'].astype(int)\nX_test_fe['Is_Other_Visitor'] = (X_test_fe['VisitorType'] != 'Returning_Visitor') & (X_test_fe['VisitorType'] != 'New_Visitor')\nX_test_fe['Is_Other_Visitor'] = X_test_fe['Is_Other_Visitor'].astype(int)\nprint(\"   âœ“ Is_Other_Visitor: binary indicator of other visitor types\")\n\n# ===== 6. WEEKEND/WEEKDAY FEATURES =====\nprint(\"\\n6. Temporal Patterns:\")\n\n# Is weekend indicator\nX_train_fe['Is_Weekend'] = X_train_fe['Weekend'].astype(int)\nX_test_fe['Is_Weekend'] = X_test_fe['Weekend'].astype(int)\nprint(\"   âœ“ Is_Weekend: binary indicator (already categorical)\")\n\n# ===== 7. INTERACTION FEATURES =====\nprint(\"\\n7. Interaction Features:\")\n\n# Product focus (product pages > info pages)\nX_train_fe['Product_Focused'] = (X_train_fe['ProductRelated'] > X_train_fe['Informational']).astype(int)\nX_test_fe['Product_Focused'] = (X_test_fe['ProductRelated'] > X_test_fe['Informational']).astype(int)\nprint(\"   âœ“ Product_Focused: user focused more on products than info\")\n\n# Active visitor (high engagement)\nX_train_fe['High_Engagement'] = (X_train_fe['Total_Duration'] > X_train_fe['Total_Duration'].median()).astype(int)\nX_test_fe['High_Engagement'] = (X_test_fe['Total_Duration'] > X_test_fe['Total_Duration'].median()).astype(int)\nprint(\"   âœ“ High_Engagement: above median engagement\")\n\n# Diverse visitor (visited multiple page types)\nX_train_fe['Diverse_Visitor'] = ((X_train_fe['Administrative'] > 0).astype(int) + \n                                  (X_train_fe['Informational'] > 0).astype(int) + \n                                  (X_train_fe['ProductRelated'] > 0).astype(int))\nX_test_fe['Diverse_Visitor'] = ((X_test_fe['Administrative'] > 0).astype(int) + \n                                 (X_test_fe['Informational'] > 0).astype(int) + \n                                 (X_test_fe['ProductRelated'] > 0).astype(int))\nprint(\"   âœ“ Diverse_Visitor: count of distinct page types visited\")\n\n# Stability indicator (small difference between bounce and exit rates)\nX_train_fe['Stable_User'] = (np.abs(X_train_fe['ExitRates'] - X_train_fe['BounceRates']) < 0.1).astype(int)\nX_test_fe['Stable_User'] = (np.abs(X_test_fe['ExitRates'] - X_test_fe['BounceRates']) < 0.1).astype(int)\nprint(\"   âœ“ Stable_User: exit and bounce rates are similar\")\n\n# ===== 8. DEVICE/BROWSER FEATURES =====\nprint(\"\\n8. Device/Browser Features:\")\n\n# High OS count (many possible OSes, often bots)\nX_train_fe['High_OS_Count'] = (X_train_fe['OperatingSystems'] > 5).astype(int)\nX_test_fe['High_OS_Count'] = (X_test_fe['OperatingSystems'] > 5).astype(int)\nprint(\"   âœ“ High_OS_Count: unusual OS patterns (potential bot indicator)\")\n\n# Common browser usage\nX_train_fe['Browser_1_or_2'] = X_train_fe['Browser'].isin([1.0, 2.0]).astype(int)\nX_test_fe['Browser_1_or_2'] = X_test_fe['Browser'].isin([1.0, 2.0]).astype(int)\nprint(\"   âœ“ Browser_1_or_2: uses most common browsers\")\n\n# ===== 9. REGIONAL FEATURES =====\nprint(\"\\n9. Regional Features:\")\n\n# Top regions (assuming regions 1-3 are high value)\nX_train_fe['Top_Region'] = (X_train_fe['Region'] <= 3).astype(int)\nX_test_fe['Top_Region'] = (X_test_fe['Region'] <= 3).astype(int)\nprint(\"   âœ“ Top_Region: from high-volume regions\")\n\n# Traffic type classification\nX_train_fe['Direct_Traffic'] = (X_train_fe['TrafficType'] == 1.0).astype(int)\nX_test_fe['Direct_Traffic'] = (X_test_fe['TrafficType'] == 1.0).astype(int)\nprint(\"   âœ“ Direct_Traffic: direct traffic indicator\")\n\n# ===== 10. COMPOSITE SCORING FEATURES =====\nprint(\"\\n10. Composite Scoring Features:\")\n\n# Purchase likelihood score (higher product ratio + higher value + lower bounce)\nX_train_fe['Purchase_Score'] = (X_train_fe['Product_Ratio'] * 3 + \n                                 X_train_fe['Revenue_Per_Visit'] * 2 + \n                                 (1 - X_train_fe['BounceRates']))\nX_test_fe['Purchase_Score'] = (X_test_fe['Product_Ratio'] * 3 + \n                                X_test_fe['Revenue_Per_Visit'] * 2 + \n                                (1 - X_test_fe['BounceRates']))\nprint(\"   âœ“ Purchase_Score: composite purchase likelihood\")\n\n# Engagement score\nX_train_fe['Engagement_Score'] = (X_train_fe['Total_Duration'] / (X_train_fe['Total_Duration'].max() + 1) * 2 +\n                                   X_train_fe['Total_Pages'] / (X_train_fe['Total_Pages'].max() + 1) +\n                                   X_train_fe['User_Quality'])\nX_test_fe['Engagement_Score'] = (X_test_fe['Total_Duration'] / (X_test_fe['Total_Duration'].max() + 1) * 2 +\n                                  X_test_fe['Total_Pages'] / (X_test_fe['Total_Pages'].max() + 1) +\n                                  X_test_fe['User_Quality'])\nprint(\"   âœ“ Engagement_Score: composite engagement metric\")\n\n# Visitor value score\nX_train_fe['Visitor_Value_Score'] = (X_train_fe['PageValues'] / (X_train_fe['PageValues'].max() + 1) * 3 +\n                                      X_train_fe['Engagement_Score'])\nX_test_fe['Visitor_Value_Score'] = (X_test_fe['PageValues'] / (X_test_fe['PageValues'].max() + 1) * 3 +\n                                     X_test_fe['Engagement_Score'])\nprint(\"   âœ“ Visitor_Value_Score: overall visitor value\")\n\n# ===== 11. POLYNOMIAL FEATURES (For Important Variables) =====\nprint(\"\\n11. Polynomial Features:\")\n\n# Square of key metrics\nX_train_fe['PageValues_Squared'] = X_train_fe['PageValues'] ** 2\nX_test_fe['PageValues_Squared'] = X_test_fe['PageValues'] ** 2\nprint(\"   âœ“ PageValues_Squared: polynomial expansion\")\n\nX_train_fe['ExitRates_Squared'] = X_train_fe['ExitRates'] ** 2\nX_test_fe['ExitRates_Squared'] = X_test_fe['ExitRates'] ** 2\nprint(\"   âœ“ ExitRates_Squared: polynomial expansion\")\n\nX_train_fe['BounceRates_Squared'] = X_train_fe['BounceRates'] ** 2\nX_test_fe['BounceRates_Squared'] = X_test_fe['BounceRates'] ** 2\nprint(\"   âœ“ BounceRates_Squared: polynomial expansion\")\n\n# ===== 12. OUTLIER DETECTION FEATURES =====\nprint(\"\\n12. Outlier Detection Features:\")\n\n# Very high exit rate (unusual behavior)\nX_train_fe['Very_High_ExitRate'] = (X_train_fe['ExitRates'] > 0.5).astype(int)\nX_test_fe['Very_High_ExitRate'] = (X_test_fe['ExitRates'] > 0.5).astype(int)\nprint(\"   âœ“ Very_High_ExitRate: indicates anomalous behavior\")\n\n# Perfect bounce rate (all bounces)\nX_train_fe['Perfect_Bounce'] = (X_train_fe['BounceRates'] == 1.0).astype(int)\nX_test_fe['Perfect_Bounce'] = (X_test_fe['BounceRates'] == 1.0).astype(int)\nprint(\"   âœ“ Perfect_Bounce: all pages bounced\")\n\n# Zero engagement\nX_train_fe['Zero_Engagement'] = ((X_train_fe['Total_Pages'] == 0) & (X_train_fe['Total_Duration'] == 0)).astype(int)\nX_test_fe['Zero_Engagement'] = ((X_test_fe['Total_Pages'] == 0) & (X_test_fe['Total_Duration'] == 0)).astype(int)\nprint(\"   âœ“ Zero_Engagement: no page visits or time spent\")\n\n# Update original datasets with engineered features\nX_train = X_train_fe.copy()\nX_test = X_test_fe.copy()\n\nprint(f\"\\n{'='*80}\")\nprint(f\"FEATURE ENGINEERING COMPLETE!\")\nprint(f\"{'='*80}\")\nprint(f\"New features created: {X_train.shape[1] - len(X_train_fe.columns) + len(X_train_fe.columns)}\")\nprint(f\"Total features now: {X_train.shape[1]}\")\nprint(f\"Train shape: {X_train.shape}\")\nprint(f\"Test shape: {X_test.shape}\")\nprint(f\"\\nNew feature columns:\")\nfor col in X_train.columns:\n    if col not in X_train_encoded.columns and col not in categorical_cols:\n        print(f\"  âœ“ {col}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:48.341827Z","iopub.execute_input":"2026-01-09T05:45:48.342170Z","iopub.status.idle":"2026-01-09T05:45:48.438670Z","shell.execute_reply.started":"2026-01-09T05:45:48.342144Z","shell.execute_reply":"2026-01-09T05:45:48.437904Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCOMPREHENSIVE FEATURE ENGINEERING\n================================================================================\n\nStarting features: 17\n\n1. Page Engagement Features:\n   âœ“ Total_Pages: sum of all page types visited\n   âœ“ Total_Duration: sum of all time spent\n   âœ“ Avg_Time_Per_Page: average time spent per page visit\n   âœ“ Admin_Ratio: proportion of admin pages\n   âœ“ Info_Ratio: proportion of informational pages\n   âœ“ Product_Ratio: proportion of product pages\n   âœ“ Admin_Time_Ratio: proportion of time on admin pages\n   âœ“ Product_Time_Ratio: proportion of time on product pages\n\n2. User Behavior Quality Features:\n   âœ“ Exit_Bounce_Diff: difference between exit and bounce rates\n   âœ“ Abandonment_Risk: combined exit and bounce rates\n   âœ“ User_Quality: inverse of bounce rate\n\n3. Monetary Value Features:\n   âœ“ Admin_Value_Per_Page: revenue potential per admin page\n   âœ“ Product_Value_Per_Page: revenue potential per product page\n   âœ“ Revenue_Per_Visit: revenue per page visit\n   âœ“ Revenue_Per_Minute: revenue efficiency by time\n   âœ“ Has_PageValue: binary indicator of any page value\n\n4. Temporal Features:\n   âœ“ Is_SpecialDay: binary indicator of special day event\n   âœ“ SpecialDay_Intensity: quadratic special day feature\n\n5. Visitor Type Features:\n   âœ“ Is_Returning: binary indicator of returning visitor\n   âœ“ Is_NewVisitor: binary indicator of new visitor\n   âœ“ Is_Other_Visitor: binary indicator of other visitor types\n\n6. Temporal Patterns:\n   âœ“ Is_Weekend: binary indicator (already categorical)\n\n7. Interaction Features:\n   âœ“ Product_Focused: user focused more on products than info\n   âœ“ High_Engagement: above median engagement\n   âœ“ Diverse_Visitor: count of distinct page types visited\n   âœ“ Stable_User: exit and bounce rates are similar\n\n8. Device/Browser Features:\n   âœ“ High_OS_Count: unusual OS patterns (potential bot indicator)\n   âœ“ Browser_1_or_2: uses most common browsers\n\n9. Regional Features:\n   âœ“ Top_Region: from high-volume regions\n   âœ“ Direct_Traffic: direct traffic indicator\n\n10. Composite Scoring Features:\n   âœ“ Purchase_Score: composite purchase likelihood\n   âœ“ Engagement_Score: composite engagement metric\n   âœ“ Visitor_Value_Score: overall visitor value\n\n11. Polynomial Features:\n   âœ“ PageValues_Squared: polynomial expansion\n   âœ“ ExitRates_Squared: polynomial expansion\n   âœ“ BounceRates_Squared: polynomial expansion\n\n12. Outlier Detection Features:\n   âœ“ Very_High_ExitRate: indicates anomalous behavior\n   âœ“ Perfect_Bounce: all pages bounced\n   âœ“ Zero_Engagement: no page visits or time spent\n\n================================================================================\nFEATURE ENGINEERING COMPLETE!\n================================================================================\nNew features created: 56\nTotal features now: 56\nTrain shape: (9880, 56)\nTest shape: (2470, 56)\n\nNew feature columns:\n  âœ“ Total_Pages\n  âœ“ Total_Duration\n  âœ“ Avg_Time_Per_Page\n  âœ“ Admin_Ratio\n  âœ“ Info_Ratio\n  âœ“ Product_Ratio\n  âœ“ Admin_Time_Ratio\n  âœ“ Product_Time_Ratio\n  âœ“ Exit_Bounce_Diff\n  âœ“ Abandonment_Risk\n  âœ“ User_Quality\n  âœ“ Admin_Value_Per_Page\n  âœ“ Product_Value_Per_Page\n  âœ“ Revenue_Per_Visit\n  âœ“ Revenue_Per_Minute\n  âœ“ Has_PageValue\n  âœ“ Is_SpecialDay\n  âœ“ SpecialDay_Intensity\n  âœ“ Is_Returning\n  âœ“ Is_NewVisitor\n  âœ“ Is_Other_Visitor\n  âœ“ Is_Weekend\n  âœ“ Product_Focused\n  âœ“ High_Engagement\n  âœ“ Diverse_Visitor\n  âœ“ Stable_User\n  âœ“ High_OS_Count\n  âœ“ Browser_1_or_2\n  âœ“ Top_Region\n  âœ“ Direct_Traffic\n  âœ“ Purchase_Score\n  âœ“ Engagement_Score\n  âœ“ Visitor_Value_Score\n  âœ“ PageValues_Squared\n  âœ“ ExitRates_Squared\n  âœ“ BounceRates_Squared\n  âœ“ Very_High_ExitRate\n  âœ“ Perfect_Bounce\n  âœ“ Zero_Engagement\n","output_type":"stream"}],"execution_count":10},{"id":"042dd3b5","cell_type":"markdown","source":"## 5. Encode Categorical Variables","metadata":{}},{"id":"41b128fb","cell_type":"code","source":"# Encode categorical variables for tree-based models\nX_train_processed = X_train.copy()\nX_test_processed = X_test.copy()\n\nprint(f\"{'='*60}\")\nprint(\"Encoding categorical features with Label Encoding\")\nprint(f\"{'='*60}\")\nfor col in categorical_cols:\n    le = LabelEncoder()\n    # Fit on combined train and test data to ensure consistency\n    combined = pd.concat([X_train_processed[col], X_test_processed[col]], axis=0)\n    le.fit(combined)\n    \n    X_train_processed[col] = le.transform(X_train_processed[col])\n    X_test_processed[col] = le.transform(X_test_processed[col])\n    label_encoders[col] = le\n\nprint(f\"\\nâœ“ Processed train shape: {X_train_processed.shape}\")\nprint(f\"âœ“ Processed test shape: {X_test_processed.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:52.626014Z","iopub.execute_input":"2026-01-09T05:45:52.626727Z","iopub.status.idle":"2026-01-09T05:45:52.640572Z","shell.execute_reply.started":"2026-01-09T05:45:52.626703Z","shell.execute_reply":"2026-01-09T05:45:52.639823Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEncoding categorical features with Label Encoding\n============================================================\n\nâœ“ Processed train shape: (9880, 56)\nâœ“ Processed test shape: (2470, 56)\n","output_type":"stream"}],"execution_count":11},{"id":"5c1bf41f","cell_type":"markdown","source":"## 6. Define CV","metadata":{}},{"id":"fc489ed9","cell_type":"code","source":"# Cross-Validation\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Setup cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:45:54.267391Z","iopub.execute_input":"2026-01-09T05:45:54.267962Z","iopub.status.idle":"2026-01-09T05:45:54.271646Z","shell.execute_reply.started":"2026-01-09T05:45:54.267936Z","shell.execute_reply":"2026-01-09T05:45:54.270853Z"}},"outputs":[],"execution_count":12},{"id":"a6bb3523","cell_type":"code","source":"# K-Fold XGBoost Models with Categorical Features (SAVE MODELS)\nprint(\"=\" * 80)\nprint(\"K-FOLD XGBOOST WITH CATEGORICAL FEATURES - SAVE MODELS\")\nprint(\"=\" * 80)\n\nxgboost_models = []\nxgboost_cv_accuracies = []\n\nprint(\"\\nTraining 5 XGBoost models with K-fold CV...\\n\")\n\nfold_num = 1\nfor train_idx, val_idx in cv.split(X_train_processed, y_train):\n    X_train_fold = X_train_processed.iloc[train_idx].copy()\n    y_train_fold = y_train.iloc[train_idx]\n    X_val_fold = X_train_processed.iloc[val_idx].copy()\n    y_val_fold = y_train.iloc[val_idx]\n    \n    # ===== XGBOOST TRAINING =====\n    # Train XGBoost\n    xgb_model = XGBClassifier(\n        n_estimators=500,\n        max_depth=8,\n        learning_rate=0.05,  \n        subsample=0.8, \n        colsample_bytree=0.9,  # Column sampling per tree\n        colsample_bylevel=0.9,  # Column sampling per (depth) level\n        min_child_weight=10,  \n        gamma=1,  \n        reg_lambda=8,  \n        reg_alpha=0,  \n        random_state=42,\n        verbosity=0,\n        eval_metric='logloss',\n        early_stopping_rounds=50,\n        use_label_encoder=False,\n    )\n    \n    xgb_model.fit(\n        X_train_fold, y_train_fold,\n        eval_set=[(X_val_fold, y_val_fold)],\n        verbose=False\n    )\n    \n    # Evaluate XGBoost on validation fold\n    y_val_pred_xgb = xgb_model.predict(X_val_fold)\n    fold_accuracy_xgb = accuracy_score(y_val_fold, y_val_pred_xgb)\n    xgboost_cv_accuracies.append(fold_accuracy_xgb)\n    xgboost_models.append(xgb_model)\n    \n    print(f\"Fold {fold_num}: XGBoost Accuracy = {fold_accuracy_xgb:.6f}\")\n    fold_num += 1\n\nprint(f\"\\n{'='*80}\")\nprint(f\"K-Fold Summary:\")\nprint(f\"{'='*80}\")\nprint(f\"\\nXGBoost:\")\nprint(f\"  Mean Accuracy: {np.mean(xgboost_cv_accuracies):.6f}\")\nprint(f\"  Std Accuracy:  {np.std(xgboost_cv_accuracies):.6f}\")\nprint(f\"  Models saved:  {len(xgboost_models)}\")\nprint(f\"{'='*80}\")\n\n# Extract best iterations from XGBoost fold models\nprint(f\"\\n{'='*80}\")\nprint(f\"EXTRACTING BEST ITERATIONS FROM XGBOOST K-FOLD MODELS\")\nprint(f\"{'='*80}\\n\")\n\nbest_iterations_xgb = []\nfor i, xgb_model in enumerate(xgboost_models):\n    best_iter = xgb_model.best_iteration\n    best_iterations_xgb.append(best_iter)\n    print(f\"Fold {i+1}: Best Iteration = {best_iter}\")\n\navg_best_iteration_xgb = np.mean(best_iterations_xgb)\noptimized_iterations_xgb = int(avg_best_iteration_xgb * 1.15)\n\nprint(f\"\\n{'='*80}\")\nprint(f\"Average Best Iteration: {avg_best_iteration_xgb:.2f}\")\nprint(f\"Optimized Iterations (avg Ã— 1.15): {optimized_iterations_xgb}\")\nprint(f\"{'='*80}\")\n\n# Train full-dataset XGBoost model with optimized iterations\nprint(f\"\\nTraining XGBoost on FULL dataset with {optimized_iterations_xgb} iterations...\\n\")\n\nxgboost_full_model = XGBClassifier(\n    n_estimators=optimized_iterations_xgb,\n    max_depth=8,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    colsample_bylevel=0.9,\n    min_child_weight=10,\n    gamma=1,\n    reg_lambda=8,\n    reg_alpha=0,\n    random_state=42,\n    verbosity=0,\n    use_label_encoder=False,\n)\n\nxgboost_full_model.fit(X_train_processed, y_train)\n\nprint(f\"âœ“ XGBoost Full-dataset model trained successfully!\")\nprint(f\"  Total training samples: {len(X_train_processed)}\")\nprint(f\"  Iterations used: {optimized_iterations_xgb}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:46:48.980733Z","iopub.execute_input":"2026-01-09T05:46:48.981043Z","iopub.status.idle":"2026-01-09T05:46:52.953415Z","shell.execute_reply.started":"2026-01-09T05:46:48.981022Z","shell.execute_reply":"2026-01-09T05:46:52.952822Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nK-FOLD XGBOOST WITH CATEGORICAL FEATURES - SAVE MODELS\n================================================================================\n\nTraining 5 XGBoost models with K-fold CV...\n\nFold 1: XGBoost Accuracy = 0.906377\nFold 2: XGBoost Accuracy = 0.903846\nFold 3: XGBoost Accuracy = 0.895749\nFold 4: XGBoost Accuracy = 0.900810\nFold 5: XGBoost Accuracy = 0.906377\n\n================================================================================\nK-Fold Summary:\n================================================================================\n\nXGBoost:\n  Mean Accuracy: 0.902632\n  Std Accuracy:  0.004005\n  Models saved:  5\n================================================================================\n\n================================================================================\nEXTRACTING BEST ITERATIONS FROM XGBOOST K-FOLD MODELS\n================================================================================\n\nFold 1: Best Iteration = 128\nFold 2: Best Iteration = 109\nFold 3: Best Iteration = 100\nFold 4: Best Iteration = 79\nFold 5: Best Iteration = 102\n\n================================================================================\nAverage Best Iteration: 103.60\nOptimized Iterations (avg Ã— 1.2): 124\n================================================================================\n\nTraining XGBoost on FULL dataset with 124 iterations...\n\nâœ“ XGBoost Full-dataset model trained successfully!\n  Total training samples: 9880\n  Iterations used: 124\n","output_type":"stream"}],"execution_count":14},{"id":"d549babd","cell_type":"markdown","source":"## 7. Create Submission File","metadata":{}},{"id":"ce72d8b6","cell_type":"code","source":"# Create submission file with XGBoost predictions only\nprint(\"=\" * 80)\nprint(\"CREATING SUBMISSION FILE - XGBOOST PREDICTIONS ONLY\")\nprint(\"=\" * 80)\n\n# Get XGBoost predictions on test set\ny_pred_xgb = xgboost_full_model.predict(X_test_processed)\n\nprint(f\"\\nXGBoost Prediction Distribution:\")\nxgb_class_0 = np.sum(y_pred_xgb == 0)\nxgb_class_1 = np.sum(y_pred_xgb == 1)\nprint(f\"  - Class 0 (No Revenue): {xgb_class_0} samples ({100*xgb_class_0/len(y_pred_xgb):.2f}%)\")\nprint(f\"  - Class 1 (Revenue):    {xgb_class_1} samples ({100*xgb_class_1/len(y_pred_xgb):.2f}%)\")\n\n# Create submission dataframe\nsubmission_df = pd.DataFrame({\n    'ID': test_ids,\n    'Revenue': y_pred_xgb\n})\n\n# Save submission file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(f\"\\nâœ“ Submission file created successfully!\")\nprint(f\"\\nFirst few rows of submission:\")\nprint(submission_df.head(10))\nprint(f\"\\nSubmission shape: {submission_df.shape}\")\nprint(f\"File saved as: submission.csv\")\nprint(\"=\" * 80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T05:46:56.288100Z","iopub.execute_input":"2026-01-09T05:46:56.288875Z","iopub.status.idle":"2026-01-09T05:46:56.321824Z","shell.execute_reply.started":"2026-01-09T05:46:56.288837Z","shell.execute_reply":"2026-01-09T05:46:56.320768Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCREATING SUBMISSION FILE - XGBOOST PREDICTIONS ONLY\n================================================================================\n\nXGBoost Prediction Distribution:\n  - Class 0 (No Revenue): 2183 samples (88.38%)\n  - Class 1 (Revenue):    287 samples (11.62%)\n\nâœ“ Submission file created successfully!\n\nFirst few rows of submission:\n   ID  Revenue\n0   0        1\n1   1        1\n2   2        0\n3   3        0\n4   4        0\n5   5        0\n6   6        0\n7   7        1\n8   8        0\n9   9        0\n\nSubmission shape: (2470, 2)\nFile saved as: submission.csv\n================================================================================\n","output_type":"stream"}],"execution_count":15},{"id":"445cec5a-0ae8-456d-8d50-f7ea83138d6a","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}