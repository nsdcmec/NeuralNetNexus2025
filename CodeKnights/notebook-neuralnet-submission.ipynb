{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127042,"databundleVersionId":15195470,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:07:57.450534Z","iopub.execute_input":"2026-01-09T17:07:57.450795Z","iopub.status.idle":"2026-01-09T17:07:58.990343Z","shell.execute_reply.started":"2026-01-09T17:07:57.450768Z","shell.execute_reply":"2026-01-09T17:07:58.988841Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/neural-net-nexus-2-0/sample_submission.csv\n/kaggle/input/neural-net-nexus-2-0/train.csv\n/kaggle/input/neural-net-nexus-2-0/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Data handling libraries\nimport pandas as pd\nimport numpy as np\n\n# Cross-validation\nfrom sklearn.model_selection import StratifiedKFold\n\n# Machine learning models\nfrom sklearn.ensemble import HistGradientBoostingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# Data preprocessing\nfrom sklearn.impute import SimpleImputer\n\n# Model evaluation metrics\nfrom sklearn.metrics import accuracy_score, precision_score\n\n# Model saving\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:18:13.080828Z","iopub.execute_input":"2026-01-09T17:18:13.081297Z","iopub.status.idle":"2026-01-09T17:18:13.087449Z","shell.execute_reply.started":"2026-01-09T17:18:13.081243Z","shell.execute_reply":"2026-01-09T17:18:13.086487Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Load CSV files from Kaggle input directory\ntrain = pd.read_csv(\"/kaggle/input/neural-net-nexus-2-0/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/neural-net-nexus-2-0/test.csv\")\n\n# Separate input features and target label\nX = train.drop(columns=[\"Revenue\"])\ny = train[\"Revenue\"].astype(int)\n\n# Create a copy of test features for final prediction\nX_test = test.copy()\n\nprint(\"Training data shape:\", train.shape)\nprint(\"Test data shape:\", test.shape)\nprint(\"\\nTarget value distribution:\")\nprint(y.value_counts())\nX.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:19:43.031174Z","iopub.execute_input":"2026-01-09T17:19:43.031674Z","iopub.status.idle":"2026-01-09T17:19:43.122363Z","shell.execute_reply.started":"2026-01-09T17:19:43.031643Z","shell.execute_reply":"2026-01-09T17:19:43.121260Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (9880, 18)\nTest data shape: (2470, 18)\n\nTarget value distribution:\nRevenue\n0    8342\n1    1538\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   Administrative  Administrative_Duration  Informational  \\\n0             0.0                      0.0            0.0   \n1             2.0                    179.0            1.0   \n2             0.0                      0.0            0.0   \n3             8.0                    144.5            4.0   \n4             0.0                      0.0            0.0   \n\n   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n0                0.000000            25.0               686.500000   \n1                0.000000             2.0               163.000000   \n2                0.000000            12.0               168.000000   \n3              181.722222            52.0              2826.790048   \n4                0.000000            11.0               210.000000   \n\n   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n0     0.016000   0.032000         0.0         0.0   Dec               2.0   \n1     0.000000   0.040000         0.0         0.0   May               1.0   \n2     0.041667   0.063889         0.0         0.0   Nov               2.0   \n3     0.007258   0.030061         0.0         0.0   May               3.0   \n4     0.009091   0.024242         0.0         0.0   May               2.0   \n\n   Browser  Region  TrafficType        VisitorType Weekend  \n0      2.0     7.0          1.0  Returning_Visitor    True  \n1      1.0     3.0          2.0        New_Visitor   False  \n2      2.0     1.0          1.0  Returning_Visitor   False  \n3      2.0     3.0         13.0  Returning_Visitor    True  \n4      2.0     8.0          2.0  Returning_Visitor   False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Administrative</th>\n      <th>Administrative_Duration</th>\n      <th>Informational</th>\n      <th>Informational_Duration</th>\n      <th>ProductRelated</th>\n      <th>ProductRelated_Duration</th>\n      <th>BounceRates</th>\n      <th>ExitRates</th>\n      <th>PageValues</th>\n      <th>SpecialDay</th>\n      <th>Month</th>\n      <th>OperatingSystems</th>\n      <th>Browser</th>\n      <th>Region</th>\n      <th>TrafficType</th>\n      <th>VisitorType</th>\n      <th>Weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>25.0</td>\n      <td>686.500000</td>\n      <td>0.016000</td>\n      <td>0.032000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Dec</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>Returning_Visitor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>179.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>163.000000</td>\n      <td>0.000000</td>\n      <td>0.040000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>May</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>New_Visitor</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>12.0</td>\n      <td>168.000000</td>\n      <td>0.041667</td>\n      <td>0.063889</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Nov</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>Returning_Visitor</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.0</td>\n      <td>144.5</td>\n      <td>4.0</td>\n      <td>181.722222</td>\n      <td>52.0</td>\n      <td>2826.790048</td>\n      <td>0.007258</td>\n      <td>0.030061</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>May</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>13.0</td>\n      <td>Returning_Visitor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.0</td>\n      <td>210.000000</td>\n      <td>0.009091</td>\n      <td>0.024242</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>May</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>Returning_Visitor</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def engineer_features(df):\n    \n    # Apply log transformation to reduce skewness in PageValues\n    df[\"PageValue_Log\"] = np.log1p(df[\"PageValues\"])\n    \n    # Compute total number of pages visited in a session\n    df[\"Total_Pages\"] = (\n        df[\"Administrative\"] +\n        df[\"Informational\"] +\n        df[\"ProductRelated\"]\n    )\n    \n    # Calculate engagement quality ratio\n    df[\"Product_Duration_Ratio\"] = (\n        df[\"ProductRelated_Duration\"] / (df[\"Total_Pages\"] + 1)\n    )\n    \n    # Identify high-conversion (peak) months\n    df[\"Is_Peak_Month\"] = df[\"Month\"].isin([\"Nov\", \"Dec\", \"May\"]).astype(int)\n    \n    # Detect high-intent users\n    df[\"High_Intent\"] = (\n        (df[\"PageValues\"] > 0) &\n        (df[\"ExitRates\"] < 0.02)\n    ).astype(int)\n    \n    # Drop low-importance/noisy categorical features\n    cols_to_drop = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\"]\n    return df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n\n# Apply feature engineering to training and test datasets\nX = engineer_features(X)\nX_test = engineer_features(X_test)\n\nprint(\"Training features shape after engineering:\", X.shape)\nprint(\"Test features shape after engineering:\", X_test.shape)\n# Display newly created features to verify correctness\nX[[\n    \"PageValue_Log\",\n    \"Total_Pages\",\n    \"Product_Duration_Ratio\",\n    \"Is_Peak_Month\",\n    \"High_Intent\"\n]].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:20:59.148343Z","iopub.execute_input":"2026-01-09T17:20:59.148707Z","iopub.status.idle":"2026-01-09T17:20:59.176597Z","shell.execute_reply.started":"2026-01-09T17:20:59.148680Z","shell.execute_reply":"2026-01-09T17:20:59.175528Z"}},"outputs":[{"name":"stdout","text":"Training features shape after engineering: (9880, 18)\nTest features shape after engineering: (2470, 19)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   PageValue_Log  Total_Pages  Product_Duration_Ratio  Is_Peak_Month  \\\n0            0.0         25.0               26.403846              1   \n1            0.0          5.0               27.166667              1   \n2            0.0         12.0               12.923077              1   \n3            0.0         64.0               43.489078              1   \n4            0.0         11.0               17.500000              1   \n\n   High_Intent  \n0            0  \n1            0  \n2            0  \n3            0  \n4            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PageValue_Log</th>\n      <th>Total_Pages</th>\n      <th>Product_Duration_Ratio</th>\n      <th>Is_Peak_Month</th>\n      <th>High_Intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>26.403846</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>27.166667</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>12.923077</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>64.0</td>\n      <td>43.489078</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>17.500000</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Apply one-hot encoding to categorical features\nX = pd.get_dummies(X)\nX_test = pd.get_dummies(X_test)\n\n# Align train and test columns to prevent mismatch errors\nX, X_test = X.align(X_test, join=\"left\", axis=1, fill_value=0)\n\nprint(\"Training feature matrix shape after encoding:\", X.shape)\nprint(\"Test feature matrix shape after encoding:\", X_test.shape)\nprint(\"Number of columns difference:\", X.shape[1] - X_test.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:21:48.341826Z","iopub.execute_input":"2026-01-09T17:21:48.342173Z","iopub.status.idle":"2026-01-09T17:21:48.353771Z","shell.execute_reply.started":"2026-01-09T17:21:48.342146Z","shell.execute_reply":"2026-01-09T17:21:48.352597Z"}},"outputs":[{"name":"stdout","text":"Training feature matrix shape after encoding: (9880, 30)\nTest feature matrix shape after encoding: (2470, 30)\nNumber of columns difference: 0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Initialize median imputer\nimputer = SimpleImputer(strategy=\"median\")\n\n# Fit on training data and transform both train and test\nX_final = imputer.fit_transform(X)\nX_test_final = imputer.transform(X_test)\n\nprint(\"Shape of training data after imputation:\", X_final.shape)\nprint(\"Shape of test data after imputation:\", X_test_final.shape)\nprint(\"Missing values in training data:\", np.isnan(X_final).sum())\nprint(\"Missing values in test data:\", np.isnan(X_test_final).sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:22:34.711297Z","iopub.execute_input":"2026-01-09T17:22:34.712248Z","iopub.status.idle":"2026-01-09T17:22:34.783119Z","shell.execute_reply.started":"2026-01-09T17:22:34.712193Z","shell.execute_reply":"2026-01-09T17:22:34.782296Z"}},"outputs":[{"name":"stdout","text":"Shape of training data after imputation: (9880, 30)\nShape of test data after imputation: (2470, 30)\nMissing values in training data: 0\nMissing values in test data: 0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Initialize 5-fold stratified cross-validation\nskf = StratifiedKFold(\n    n_splits=5,\n    shuffle=True,\n    random_state=42\n)\n\n# Containers to store predictions and scores\ntest_probs = np.zeros(len(X_test_final))\nval_scores = []\n\nprint(\"Number of folds:\", skf.get_n_splits())\nprint(\"Number of test samples:\", len(test_probs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:23:24.693156Z","iopub.execute_input":"2026-01-09T17:23:24.694530Z","iopub.status.idle":"2026-01-09T17:23:24.700853Z","shell.execute_reply.started":"2026-01-09T17:23:24.694465Z","shell.execute_reply":"2026-01-09T17:23:24.699879Z"}},"outputs":[{"name":"stdout","text":"Number of folds: 5\nNumber of test samples: 2470\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(skf.split(X_final, y)):\n    \n    # Split data into training and validation sets\n    X_tr, X_val = X_final[train_idx], X_final[val_idx]\n    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n    \n    # Define individual models\n    xgb_model = XGBClassifier(\n        n_estimators=1000,\n        max_depth=5,\n        learning_rate=0.01,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42\n    )\n    \n    lgb_model = LGBMClassifier(\n        n_estimators=1000,\n        learning_rate=0.01,\n        num_leaves=31,\n        verbose=-1,\n        random_state=42\n    )\n    \n    hist_model = HistGradientBoostingClassifier(\n        max_iter=500,\n        learning_rate=0.01,\n        max_depth=10\n    )\n    \n    # Create soft-voting ensemble\n    model = VotingClassifier(\n        estimators=[\n            (\"xgb\", xgb_model),\n            (\"lgb\", lgb_model),\n            (\"hist\", hist_model)\n        ],\n        voting=\"soft\"\n    )\n    \n    # Train ensemble model\n    model.fit(X_tr, y_tr)\n    \n    # Validation predictions\n    val_probs = model.predict_proba(X_val)[:, 1]\n    val_preds = (val_probs > 0.45).astype(int)\n    \n    # Calculate accuracy\n    fold_acc = accuracy_score(y_val, val_preds)\n    val_scores.append(fold_acc)\n    \n    # Accumulate test probabilities\n    test_probs += model.predict_proba(X_test_final)[:, 1] / skf.n_splits\n    \n    print(f\"Fold {fold + 1} Accuracy: {fold_acc:.4f}\")\n\nprint(\"\\nMean Cross-Validation Accuracy:\", np.mean(val_scores))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:24:15.811093Z","iopub.execute_input":"2026-01-09T17:24:15.811437Z","iopub.status.idle":"2026-01-09T17:24:46.639255Z","shell.execute_reply.started":"2026-01-09T17:24:15.811408Z","shell.execute_reply":"2026-01-09T17:24:46.638348Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 Accuracy: 0.9018\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 2 Accuracy: 0.9054\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 3 Accuracy: 0.8963\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 4 Accuracy: 0.8968\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 5 Accuracy: 0.9033\n\nMean Cross-Validation Accuracy: 0.9007085020242915\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"final_threshold = 0.44\n\n# Convert probabilities to final class predictions\nfinal_preds = (test_probs >= final_threshold).astype(int)\n\nunique, counts = np.unique(final_preds, return_counts=True)\nprint(\"Final prediction distribution:\")\ndict(zip(unique, counts))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:25:38.965392Z","iopub.execute_input":"2026-01-09T17:25:38.965772Z","iopub.status.idle":"2026-01-09T17:25:38.974829Z","shell.execute_reply.started":"2026-01-09T17:25:38.965743Z","shell.execute_reply":"2026-01-09T17:25:38.973635Z"}},"outputs":[{"name":"stdout","text":"Final prediction distribution:\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{np.int64(0): np.int64(2132), np.int64(1): np.int64(338)}"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"ID\": test.index,\n    \"Revenue\": final_preds\n})\n\n# Save submission file\nsubmission.to_csv(\"submission for neural net.csv\", index=False)\n\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:28:45.451650Z","iopub.execute_input":"2026-01-09T17:28:45.452070Z","iopub.status.idle":"2026-01-09T17:28:45.471871Z","shell.execute_reply.started":"2026-01-09T17:28:45.452039Z","shell.execute_reply":"2026-01-09T17:28:45.470880Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   ID  Revenue\n0   0        1\n1   1        1\n2   2        0\n3   3        0\n4   4        0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"team_name = \"CodeKnights\"\n\n# Save the model\njoblib.dump(model, f\"{team_name}.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T17:31:43.315542Z","iopub.execute_input":"2026-01-09T17:31:43.315973Z","iopub.status.idle":"2026-01-09T17:31:43.532827Z","shell.execute_reply.started":"2026-01-09T17:31:43.315942Z","shell.execute_reply":"2026-01-09T17:31:43.531963Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['CodeKnights.joblib']"},"metadata":{}}],"execution_count":21}]}