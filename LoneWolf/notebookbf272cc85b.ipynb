{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127042,"databundleVersionId":15195470,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_score, accuracy_score\nfrom catboost import CatBoostClassifier\n\n# ==========================================\n# 1. Updated Wrapper for Ensembles\n# ==========================================\nclass LoneWolfPredictor:\n    \"\"\"\n    Unified wrapper that handles 5-Fold Ensembling for both Model A and B.\n    \"\"\"\n    def __init__(self, models_a, models_b, threshold):\n        self.models_a = models_a  # List of 5 models\n        self.models_b = models_b  # List of 5 models\n        self.threshold = threshold\n\n    def _get_avg_proba(self, models, X):\n        \"\"\"Helper to average predictions across all folds\"\"\"\n        preds = np.zeros(len(X))\n        for model in models:\n            preds += model.predict_proba(X)[:, 1]\n        return preds / len(models)\n\n    def predict(self, X):\n        # 1. Get Averaged Probs for A and B\n        prob_a = self._get_avg_proba(self.models_a, X)\n        prob_b = self._get_avg_proba(self.models_b, X)\n        \n        # 2. Blend\n        blend_prob = 0.6 * prob_a + 0.4 * prob_b\n        \n        # 3. Threshold\n        return (blend_prob >= self.threshold).astype(int)\n\n# ==========================================\n# 2. Setup Data\n# ==========================================\nTEAM_NAME = \"LoneWolf\"\nos.makedirs(TEAM_NAME, exist_ok=True)\n\ntrain_df = pd.read_csv(\"/kaggle/input/neural-net-nexus-2-0/train.csv\")\ntest_df  = pd.read_csv(\"/kaggle/input/neural-net-nexus-2-0/test.csv\")\ny = train_df[\"Revenue\"]\n\n# Feature Prep\ndf = pd.concat([train_df.drop(columns=[\"Revenue\"]), test_df.drop(columns=[\"ID\"])], axis=0).reset_index(drop=True)\ncat_features = df.select_dtypes(include=\"object\").columns.tolist()\nfor col in cat_features:\n    df[col] = df[col].fillna(\"Missing\").astype(str)\n\nX = df.iloc[:len(train_df)]\nX_test = df.iloc[len(train_df):]\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# ==========================================\n# 3. Train & Collect Ensembles\n# ==========================================\n# Lists to store all 5 models for the Joblib\nmodels_a_list = []\nmodels_b_list = []\n\n# Arrays for Inline Verification\noof_A = np.zeros(len(X))\ntest_A_inline = np.zeros(len(X_test))\noof_B = np.zeros(len(X))\ntest_B_inline = np.zeros(len(X_test))\n\nprint(\">>> Training Model A (Ensemble)...\")\nfor fold, (tr, val) in enumerate(folds.split(X, y)):\n    model = CatBoostClassifier(\n        iterations=1000, depth=6, learning_rate=0.03, # Reduced iters for speed in demo\n        loss_function=\"Logloss\", eval_metric=\"AUC\",\n        class_weights={0: 1.0, 1: 3.0}, cat_features=cat_features,\n        early_stopping_rounds=100, verbose=0, random_seed=42\n    )\n    model.fit(X.iloc[tr], y.iloc[tr], eval_set=(X.iloc[val], y.iloc[val]), use_best_model=True)\n    \n    # Save for Wrapper\n    models_a_list.append(model)\n    \n    # Save for Inline Calc\n    oof_A[val] = model.predict_proba(X.iloc[val])[:, 1]\n    test_A_inline += model.predict_proba(X_test)[:, 1] / folds.n_splits\n\nprint(\">>> Training Model B (Ensemble)...\")\nfor fold, (tr, val) in enumerate(folds.split(X, y)):\n    model = CatBoostClassifier(\n        iterations=800, depth=7, learning_rate=0.04,\n        loss_function=\"Logloss\", eval_metric=\"AUC\",\n        class_weights={0: 1.0, 1: 1.8}, cat_features=cat_features,\n        early_stopping_rounds=100, verbose=0, random_seed=24\n    )\n    model.fit(X.iloc[tr], y.iloc[tr], eval_set=(X.iloc[val], y.iloc[val]), use_best_model=True)\n    \n    # Save for Wrapper\n    models_b_list.append(model)\n    \n    # Save for Inline Calc\n    oof_B[val] = model.predict_proba(X.iloc[val])[:, 1]\n    test_B_inline += model.predict_proba(X_test)[:, 1] / folds.n_splits\n\n# ==========================================\n# 4. Optimization & Inline Prediction\n# ==========================================\noof_blend = 0.6 * oof_A + 0.4 * oof_B\nbest_t, best_score = 0.5, 0\n\nfor t in np.arange(0.3, 0.7, 0.01):\n    score = 0.5 * precision_score(y, (oof_blend >= t).astype(int)) + \\\n            0.5 * accuracy_score(y, (oof_blend >= t).astype(int))\n    if score > best_score:\n        best_t = t\n\nprint(f\"Optimal Threshold: {best_t:.4f}\")\n\n# INLINE RESULT (Manual Way)\ntest_blend_inline = 0.6 * test_A_inline + 0.4 * test_B_inline\nfinal_preds_inline = (test_blend_inline >= best_t).astype(int)\n\n# ==========================================\n# 5. Create & Verify Joblib Wrapper\n# ==========================================\n# A. Create Wrapper\nunified_model = LoneWolfPredictor(models_a_list, models_b_list, best_t)\n\n# B. Save & Reload\njoblib.dump(unified_model, f\"{TEAM_NAME}/full_ensemble.joblib\")\nloaded_model = joblib.load(f\"{TEAM_NAME}/full_ensemble.joblib\")\n\n# C. Predict using Wrapper\nfinal_preds_wrapper = loaded_model.predict(X_test)\n\n# ==========================================\n# 6. Final Verification\n# ==========================================\ncomparison = (final_preds_inline == final_preds_wrapper)\nmatch_count = np.sum(comparison)\ntotal_count = len(comparison)\n\nprint(\"-\" * 30)\nprint(f\"Inline vs Wrapper Comparison:\")\nprint(f\"Matching Predictions: {match_count} / {total_count}\")\nprint(f\"Match Percentage:     {100 * match_count / total_count:.2f}%\")\nprint(\"-\" * 30)\n\nif match_count == total_count:\n    print(\"✅ SUCCESS: The Joblib produces EXACTLY the same output.\")\nelse:\n    print(\"❌ WARNING: Outputs differ. Check floating point precision or list order.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:15:10.056914Z","iopub.execute_input":"2026-01-09T09:15:10.058236Z","iopub.status.idle":"2026-01-09T09:16:05.099149Z","shell.execute_reply.started":"2026-01-09T09:15:10.058184Z","shell.execute_reply":"2026-01-09T09:16:05.097461Z"}},"outputs":[{"name":"stdout","text":">>> Training Model A (Ensemble)...\n>>> Training Model B (Ensemble)...\nOptimal Threshold: 0.6900\n------------------------------\nInline vs Wrapper Comparison:\nMatching Predictions: 2470 / 2470\nMatch Percentage:     100.00%\n------------------------------\n✅ SUCCESS: The Joblib produces EXACTLY the same output.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==========================================\n# 7. Generate Submission CSV\n# ==========================================\nsubmission = pd.DataFrame({\n    \"ID\": test_ids,\n    \"Revenue\": final_preds_wrapper\n})\n\nsubmission_path = f\"{TEAM_NAME}/submission_blend_safe.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nprint(f\"✅ Success! Submission saved to: {submission_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:19:18.046499Z","iopub.execute_input":"2026-01-09T09:19:18.047287Z","iopub.status.idle":"2026-01-09T09:19:18.060174Z","shell.execute_reply.started":"2026-01-09T09:19:18.047241Z","shell.execute_reply":"2026-01-09T09:19:18.058697Z"}},"outputs":[{"name":"stdout","text":"✅ Success! Submission saved to: LoneWolf/submission_blend_safe.csv\n","output_type":"stream"}],"execution_count":7}]}